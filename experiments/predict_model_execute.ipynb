{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835a44d8",
   "metadata": {},
   "source": [
    "**Find Trends in the data for modeling forward pass**\n",
    "\n",
    "Similar to `experiments/step_time_analysis.ipynb` we are using current batch data we gathered in profiling to estimate forward pass times with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import parse_csv, format_data, concatenate_dataframes # found in utils.py\n",
    "\n",
    "path1 = './profiling/train'\n",
    "\n",
    "# # parse and concat all dataframes\n",
    "df = concatenate_dataframes(path1)\n",
    "df = format_data(df)\n",
    "# df.to_csv('formatted_execution_stats500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "478f4420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    execute_time  num_prefills  sum_decode_tokens  \\\n",
      "execute_time            1.000000      0.804904           0.860769   \n",
      "num_prefills            0.804904      1.000000           0.596136   \n",
      "sum_decode_tokens       0.860769      0.596136           1.000000   \n",
      "sum_prefill_tokens      0.753547      0.666530           0.434525   \n",
      "max_prefill_tokens      0.736851      0.603709           0.439435   \n",
      "\n",
      "                    sum_prefill_tokens  max_prefill_tokens  \n",
      "execute_time                  0.753547            0.736851  \n",
      "num_prefills                  0.666530            0.603709  \n",
      "sum_decode_tokens             0.434525            0.439435  \n",
      "sum_prefill_tokens            1.000000            0.964966  \n",
      "max_prefill_tokens            0.964966            1.000000  \n"
     ]
    }
   ],
   "source": [
    "# try to find correlation between execute_time and num_decodes, num_prefills, sum_decode_tokens, sum_prefill_tokens\n",
    "correlation = df[['execute_time', 'num_prefills', 'sum_decode_tokens', 'sum_prefill_tokens', 'max_prefill_tokens']].corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67510048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [7.00524792e-05 1.95214710e-08 1.09916161e-08 2.84607896e-03]\n",
      "Intercept: 0.004977576410358687\n",
      "Score: 0.9462946728871697\n"
     ]
    }
   ],
   "source": [
    "# train a linear regression model to predict execute_time based on num_prefills, sum_decode_tokens, sum_prefill_tokens, and arrival_rate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = df[['sum_decode_tokens', 'sum_prefill_tokens', 'max_prefill_tokens','num_prefills']]\n",
    "y = df['execute_time']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Score:\", model.score(X_test, y_test))\n",
    "# make predictions on the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
